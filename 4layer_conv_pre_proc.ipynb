{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2layer_conv_pre_proc.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{},"source":["## Tests on preprocessing techniques"]},{"cell_type":"markdown","metadata":{},"source":["Tests were performed on 4-layer CNN model using different preprocessing techniques with 10 epochs including:\n","- Normalization\n","- Noise removal\n","- Image augmentation\n","- Image resizing\n","- Rectangle/square bounding box"]},{"metadata":{"id":"WwoUZpDyeTWw","colab_type":"code","outputId":"ada1ec80-76b0-4ee3-bb02-7bbb2d1a9374","executionInfo":{"status":"ok","timestamp":1552874065565,"user_tz":240,"elapsed":92561,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":1020}},"cell_type":"code","source":["#directly use raw data\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        temp_images.append([])\n","        img_idx = i\n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","    \n","        \n","        #without bounding box\n","        temp_images[i] = cv2.resize(train_images[img_idx],(28,28))\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","#split data in train, validation, test\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","#pre processing it, resize it\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","# do something to fit in kera model---------------------------------------------\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","final_images = final_images.reshape(final_images.shape[0], 28, 28, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","final_images = final_images.astype('float32')\n","\n","#normalization\n","\n","\n","X_train.shape\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]\n","#------------------------------------------------------------------------------\n","\n","#2d convolution----------------------------------------------------------------\n","# Three steps to Convolution\n","# 1. Convolution\n","# 2. Activation\n","# 3. Polling\n","# Repeat Steps 1,2,3 for adding more hidden layers\n","# 4. After that make a fully connected network\n","# This fully connected network gives ability to the CNN\n","# to classify the samples\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64,(3, 3)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Flatten())\n","# Fully connected layer\n","\n","BatchNormalization()\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","#----------------------------------------------------------------------------------------\n","#generate additional images\n","\n","gen = ImageDataGenerator()\n","#--------------------------------------------------------------------------------\n","test_gen = ImageDataGenerator()\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n","\n","#model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, validation_data=(X_test, Y_test))\n","\n","#fit the data and valid\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=10,validation_data=test_generator, validation_steps=4000//64)\n","\n","#\n","score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","X_train original shape (35000, 28, 28)\n","y_train original shape (35000,)\n","X_test original shape (4000, 28, 28)\n","y_test original shape (4000,)\n","Epoch 1/10\n","546/546 [==============================] - 11s 19ms/step - loss: 2.3563 - acc: 0.1067 - val_loss: 2.3019 - val_acc: 0.1109\n","Epoch 2/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3022 - acc: 0.1083 - val_loss: 2.3009 - val_acc: 0.1105\n","Epoch 3/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3018 - acc: 0.1072 - val_loss: 2.3026 - val_acc: 0.1087\n","Epoch 4/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3022 - acc: 0.1091 - val_loss: 2.3021 - val_acc: 0.1108\n","Epoch 5/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3022 - acc: 0.1091 - val_loss: 2.3019 - val_acc: 0.1072\n","Epoch 6/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3017 - acc: 0.1093 - val_loss: 2.3010 - val_acc: 0.1148\n","Epoch 7/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3021 - acc: 0.1091 - val_loss: 2.3017 - val_acc: 0.1085\n","Epoch 8/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3018 - acc: 0.1094 - val_loss: 2.3021 - val_acc: 0.1082\n","Epoch 9/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3018 - acc: 0.1102 - val_loss: 2.3015 - val_acc: 0.1100\n","Epoch 10/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3017 - acc: 0.1084 - val_loss: 2.3016 - val_acc: 0.1100\n","4000/4000 [==============================] - 0s 105us/step\n","\n","Test accuracy:  0.11025\n"],"name":"stdout"}]},{"metadata":{"id":"0K-TkQqVoYIc","colab_type":"code","outputId":"7c7c0634-dd33-4c65-d9f4-775b67c798ef","executionInfo":{"status":"ok","timestamp":1552872332737,"user_tz":240,"elapsed":89289,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":810}},"cell_type":"code","source":["#applying normalization\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        temp_images.append([])\n","        img_idx = i\n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","    \n","        \n","        #without bounding box\n","        temp_images[i] = cv2.resize(train_images[img_idx],(28,28))\n","       \n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","\n","# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","\n","\n","#split data in train, validation, test\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","#pre processing it, resize it\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","# do something to fit in kera model---------------------------------------------\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","final_images = final_images.reshape(final_images.shape[0], 28, 28, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","final_images = final_images.astype('float32')\n","\n","#normalization\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]\n","#------------------------------------------------------------------------------\n","\n","#2d convolution----------------------------------------------------------------\n","# Three steps to Convolution\n","# 1. Convolution\n","# 2. Activation\n","# 3. Polling\n","# Repeat Steps 1,2,3 for adding more hidden layers\n","# 4. After that make a fully connected network\n","# This fully connected network gives ability to the CNN\n","# to classify the samples\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64,(3, 3)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Flatten())\n","# Fully connected layer\n","\n","BatchNormalization()\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(10))\n","\n","# model.add(Convolution2D(10,3,3, border_mode='same'))\n","# model.add(GlobalAveragePooling2D())\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","#----------------------------------------------------------------------------------------\n","#generate additional images\n","\n","gen = ImageDataGenerator()\n","#--------------------------------------------------------------------------------\n","test_gen = ImageDataGenerator()\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n","\n","#model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, validation_data=(X_test, Y_test))\n","\n","#fit the data and valid\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=10,validation_data=test_generator, validation_steps=4000//64)\n","\n","#\n","score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","X_train original shape (35000, 28, 28)\n","y_train original shape (35000,)\n","X_test original shape (4000, 28, 28)\n","y_test original shape (4000,)\n","Epoch 1/10\n","546/546 [==============================] - 9s 17ms/step - loss: 2.3024 - acc: 0.1072 - val_loss: 2.3018 - val_acc: 0.1109\n","Epoch 2/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3019 - acc: 0.1081 - val_loss: 2.3012 - val_acc: 0.1108\n","Epoch 3/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3019 - acc: 0.1101 - val_loss: 2.3018 - val_acc: 0.1085\n","Epoch 4/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3017 - acc: 0.1098 - val_loss: 2.3016 - val_acc: 0.1115\n","Epoch 5/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3018 - acc: 0.1099 - val_loss: 2.3019 - val_acc: 0.1062\n","Epoch 6/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3017 - acc: 0.1089 - val_loss: 2.3010 - val_acc: 0.1146\n","Epoch 7/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3017 - acc: 0.1099 - val_loss: 2.3022 - val_acc: 0.1075\n","Epoch 8/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3017 - acc: 0.1098 - val_loss: 2.3018 - val_acc: 0.1098\n","Epoch 9/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3017 - acc: 0.1101 - val_loss: 2.3013 - val_acc: 0.1100\n","Epoch 10/10\n","546/546 [==============================] - 8s 15ms/step - loss: 2.3016 - acc: 0.1099 - val_loss: 2.3016 - val_acc: 0.1100\n","4000/4000 [==============================] - 0s 96us/step\n","\n","Test accuracy:  0.11025\n"],"name":"stdout"}]},{"metadata":{"id":"j-O4KMsuYXOq","colab_type":"code","outputId":"b99dfa5c-296b-4877-b4aa-47ea2164690b","executionInfo":{"status":"ok","timestamp":1552872421401,"user_tz":240,"elapsed":130560,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":960}},"cell_type":"code","source":["#normalization+noise removal\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        temp_images.append([])\n","        img_idx = i\n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","        \n","        #reducing noise\n","        temp_images[i] = cv2.resize(threshed_img,(28,28))\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","\n","# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","\n","\n","#split data in train, validation, test\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","#pre processing it, resize it\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","# do something to fit in kera model---------------------------------------------\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","final_images = final_images.reshape(final_images.shape[0], 28, 28, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","final_images = final_images.astype('float32')\n","\n","#normalization\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]\n","#------------------------------------------------------------------------------\n","\n","#2d convolution----------------------------------------------------------------\n","# Three steps to Convolution\n","# 1. Convolution\n","# 2. Activation\n","# 3. Polling\n","# Repeat Steps 1,2,3 for adding more hidden layers\n","# 4. After that make a fully connected network\n","# This fully connected network gives ability to the CNN\n","# to classify the samples\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64,(3, 3)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","# Fully connected layer\n","\n","BatchNormalization()\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","#----------------------------------------------------------------------------------------\n","#generate additional images\n","\n","gen = ImageDataGenerator()\n","#--------------------------------------------------------------------------------\n","test_gen = ImageDataGenerator()\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n","\n","#model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, validation_data=(X_test, Y_test))\n","\n","#fit the data and valid\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=10,validation_data=test_generator, validation_steps=4000//64)\n","\n","#\n","score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","X_train original shape (35000, 28, 28)\n","y_train original shape (35000,)\n","X_test original shape (4000, 28, 28)\n","y_test original shape (4000,)\n","Epoch 1/10\n","546/546 [==============================] - 9s 17ms/step - loss: 1.8204 - acc: 0.3279 - val_loss: 1.0498 - val_acc: 0.6565\n","Epoch 2/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.7235 - acc: 0.7731 - val_loss: 0.5260 - val_acc: 0.8366\n","Epoch 3/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.4549 - acc: 0.8594 - val_loss: 0.4158 - val_acc: 0.8704\n","Epoch 4/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.3512 - acc: 0.8915 - val_loss: 0.3795 - val_acc: 0.8803\n","Epoch 5/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.2833 - acc: 0.9102 - val_loss: 0.3489 - val_acc: 0.8920\n","Epoch 6/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.2430 - acc: 0.9231 - val_loss: 0.3735 - val_acc: 0.8890\n","Epoch 7/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.2050 - acc: 0.9334 - val_loss: 0.3657 - val_acc: 0.8915\n","Epoch 8/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.1870 - acc: 0.9382 - val_loss: 0.3712 - val_acc: 0.8905\n","Epoch 9/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.1624 - acc: 0.9464 - val_loss: 0.3825 - val_acc: 0.9004\n","Epoch 10/10\n","546/546 [==============================] - 8s 15ms/step - loss: 0.1496 - acc: 0.9516 - val_loss: 0.3785 - val_acc: 0.8958\n","4000/4000 [==============================] - 0s 97us/step\n","\n","Test accuracy:  0.8955\n"],"name":"stdout"}]},{"metadata":{"id":"IrSGRaKooFkb","colab_type":"code","outputId":"da8bedfb-9f1e-4a41-dc2c-409835f0fbeb","executionInfo":{"status":"ok","timestamp":1552872684466,"user_tz":240,"elapsed":161845,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":1020}},"cell_type":"code","source":["#normalization+noise removal+image augmentation\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        temp_images.append([])\n","        img_idx = i\n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","             \n","        \n","        #reducing noise\n","        temp_images[i] = cv2.resize(threshed_img,(28,28))\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","#split data in train, validation, test\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","#pre processing it, resize it\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","# do something to fit in kera model---------------------------------------------\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","final_images = final_images.reshape(final_images.shape[0], 28, 28, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","final_images = final_images.astype('float32')\n","\n","#normalization\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]\n","#------------------------------------------------------------------------------\n","\n","#2d convolution----------------------------------------------------------------\n","# Three steps to Convolution\n","# 1. Convolution\n","# 2. Activation\n","# 3. Polling\n","# Repeat Steps 1,2,3 for adding more hidden layers\n","# 4. After that make a fully connected network\n","# This fully connected network gives ability to the CNN\n","# to classify the samples\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64,(3, 3)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","\n","# Fully connected layer\n","BatchNormalization()\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","#----------------------------------------------------------------------------------------\n","#generate additional images\n","\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","#--------------------------------------------------------------------------------\n","test_gen = ImageDataGenerator()\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n","\n","#model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, validation_data=(X_test, Y_test))\n","\n","#fit the data and valid\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=10,validation_data=test_generator, validation_steps=4000//64)\n","\n","#\n","score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","X_train original shape (35000, 28, 28)\n","y_train original shape (35000,)\n","X_test original shape (4000, 28, 28)\n","y_test original shape (4000,)\n","Epoch 1/10\n","546/546 [==============================] - 16s 30ms/step - loss: 2.0577 - acc: 0.2232 - val_loss: 1.4615 - val_acc: 0.4521\n","Epoch 2/10\n","546/546 [==============================] - 15s 28ms/step - loss: 1.1555 - acc: 0.6156 - val_loss: 0.7323 - val_acc: 0.7566\n","Epoch 3/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.7583 - acc: 0.7641 - val_loss: 0.5397 - val_acc: 0.8313\n","Epoch 4/10\n","546/546 [==============================] - 16s 28ms/step - loss: 0.6127 - acc: 0.8088 - val_loss: 0.3944 - val_acc: 0.8745\n","Epoch 5/10\n","546/546 [==============================] - 16s 28ms/step - loss: 0.5441 - acc: 0.8336 - val_loss: 0.3959 - val_acc: 0.8742\n","Epoch 6/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.4915 - acc: 0.8514 - val_loss: 0.3480 - val_acc: 0.8824\n","Epoch 7/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.4579 - acc: 0.8616 - val_loss: 0.3304 - val_acc: 0.8951\n","Epoch 8/10\n","546/546 [==============================] - 16s 28ms/step - loss: 0.4332 - acc: 0.8684 - val_loss: 0.3405 - val_acc: 0.8961\n","Epoch 9/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.4078 - acc: 0.8747 - val_loss: 0.3075 - val_acc: 0.9055\n","Epoch 10/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.3882 - acc: 0.8833 - val_loss: 0.3072 - val_acc: 0.9050\n","4000/4000 [==============================] - 0s 113us/step\n","\n","Test accuracy:  0.907\n"],"name":"stdout"}]},{"metadata":{"id":"wBygk25aP3Ro","colab_type":"code","outputId":"6138d7f4-c8bd-4558-8ec0-f4e571d82b9d","executionInfo":{"status":"ok","timestamp":1552926266937,"user_tz":240,"elapsed":1186664,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":1198}},"cell_type":"code","source":["#normalization+noise removal+image augmentation+resizing\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        temp_images.append([])\n","        img_idx = i\n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]] \n","        \n","        #reducing noise\n","        temp_images[i] = cv2.resize(threshed_img,(80,80))\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","\n","\n","#split data in train, validation, test\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","#pre processing it, resize it\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","# do something to fit in kera model---------------------------------------------\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 80, 80\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 80, 80, 1)\n","X_test = X_test.reshape(X_test.shape[0], 80, 80, 1)\n","\n","final_images = final_images.reshape(final_images.shape[0], 80, 80, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","final_images = final_images.astype('float32')\n","\n","#normalization\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]\n","#------------------------------------------------------------------------------\n","\n","#2d convolution----------------------------------------------------------------\n","# Three steps to Convolution\n","# 1. Convolution\n","# 2. Activation\n","# 3. Polling\n","# Repeat Steps 1,2,3 for adding more hidden layers\n","# 4. After that make a fully connected network\n","# This fully connected network gives ability to the CNN\n","# to classify the samples\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(80,80,1)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64,(3, 3)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","\n","# Fully connected layer\n","BatchNormalization()\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","#----------------------------------------------------------------------------------------\n","#generate additional images\n","\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","#--------------------------------------------------------------------------------\n","test_gen = ImageDataGenerator()\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n","\n","#fit the data and valid\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=30,validation_data=test_generator, validation_steps=4000//64)\n","\n","#\n","score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","X_train original shape (35000, 80, 80)\n","y_train original shape (35000,)\n","X_test original shape (4000, 80, 80)\n","y_test original shape (4000,)\n","Epoch 1/30\n","546/546 [==============================] - 43s 78ms/step - loss: 2.0702 - acc: 0.2339 - val_loss: 1.6735 - val_acc: 0.4052\n","Epoch 2/30\n","546/546 [==============================] - 39s 72ms/step - loss: 1.5003 - acc: 0.4865 - val_loss: 1.1749 - val_acc: 0.6080\n","Epoch 3/30\n","546/546 [==============================] - 39s 71ms/step - loss: 1.1679 - acc: 0.6155 - val_loss: 0.9150 - val_acc: 0.7068\n","Epoch 4/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.9620 - acc: 0.6901 - val_loss: 0.7367 - val_acc: 0.7683\n","Epoch 5/30\n","546/546 [==============================] - 38s 70ms/step - loss: 0.8412 - acc: 0.7315 - val_loss: 0.7077 - val_acc: 0.7779\n","Epoch 6/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.7537 - acc: 0.7579 - val_loss: 0.6155 - val_acc: 0.8117\n","Epoch 7/30\n","546/546 [==============================] - 38s 70ms/step - loss: 0.6952 - acc: 0.7767 - val_loss: 0.5529 - val_acc: 0.8323\n","Epoch 8/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.6590 - acc: 0.7914 - val_loss: 0.5386 - val_acc: 0.8364\n","Epoch 9/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.6154 - acc: 0.8031 - val_loss: 0.5319 - val_acc: 0.8364\n","Epoch 10/30\n","546/546 [==============================] - 40s 72ms/step - loss: 0.5892 - acc: 0.8124 - val_loss: 0.5160 - val_acc: 0.8384\n","Epoch 11/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.5581 - acc: 0.8233 - val_loss: 0.5132 - val_acc: 0.8397\n","Epoch 12/30\n","546/546 [==============================] - 38s 71ms/step - loss: 0.5516 - acc: 0.8229 - val_loss: 0.4787 - val_acc: 0.8529\n","Epoch 13/30\n","546/546 [==============================] - 38s 70ms/step - loss: 0.5144 - acc: 0.8346 - val_loss: 0.4603 - val_acc: 0.8529\n","Epoch 14/30\n","546/546 [==============================] - 38s 70ms/step - loss: 0.5039 - acc: 0.8373 - val_loss: 0.4436 - val_acc: 0.8659\n","Epoch 15/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.4796 - acc: 0.8477 - val_loss: 0.4597 - val_acc: 0.8537\n","Epoch 16/30\n","546/546 [==============================] - 40s 74ms/step - loss: 0.4725 - acc: 0.8487 - val_loss: 0.4341 - val_acc: 0.8623\n","Epoch 17/30\n","546/546 [==============================] - 41s 75ms/step - loss: 0.4597 - acc: 0.8521 - val_loss: 0.4175 - val_acc: 0.8694\n","Epoch 18/30\n","546/546 [==============================] - 41s 75ms/step - loss: 0.4462 - acc: 0.8571 - val_loss: 0.4083 - val_acc: 0.8661\n","Epoch 19/30\n","546/546 [==============================] - 40s 74ms/step - loss: 0.4383 - acc: 0.8603 - val_loss: 0.4259 - val_acc: 0.8666\n","Epoch 20/30\n","546/546 [==============================] - 39s 72ms/step - loss: 0.4248 - acc: 0.8643 - val_loss: 0.4137 - val_acc: 0.8768\n","Epoch 21/30\n","546/546 [==============================] - 40s 72ms/step - loss: 0.4121 - acc: 0.8662 - val_loss: 0.4154 - val_acc: 0.8720\n","Epoch 22/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.4063 - acc: 0.8686 - val_loss: 0.3879 - val_acc: 0.8798\n","Epoch 23/30\n","546/546 [==============================] - 39s 72ms/step - loss: 0.3951 - acc: 0.8723 - val_loss: 0.4059 - val_acc: 0.8768\n","Epoch 24/30\n","546/546 [==============================] - 40s 74ms/step - loss: 0.3916 - acc: 0.8759 - val_loss: 0.3901 - val_acc: 0.8747\n","Epoch 25/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.3762 - acc: 0.8803 - val_loss: 0.3985 - val_acc: 0.8768\n","Epoch 26/30\n","546/546 [==============================] - 39s 72ms/step - loss: 0.3739 - acc: 0.8794 - val_loss: 0.3977 - val_acc: 0.8712\n","Epoch 27/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.3670 - acc: 0.8815 - val_loss: 0.4213 - val_acc: 0.8699\n","Epoch 28/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.3613 - acc: 0.8827 - val_loss: 0.3550 - val_acc: 0.8831\n","Epoch 29/30\n","546/546 [==============================] - 39s 72ms/step - loss: 0.3577 - acc: 0.8845 - val_loss: 0.3945 - val_acc: 0.8801\n","Epoch 30/30\n","546/546 [==============================] - 39s 71ms/step - loss: 0.3559 - acc: 0.8855 - val_loss: 0.3724 - val_acc: 0.8864\n","4000/4000 [==============================] - 1s 365us/step\n","\n","Test accuracy:  0.88075\n"],"name":"stdout"}]},{"metadata":{"id":"aFzmanztroLM","colab_type":"code","outputId":"52e5fe2f-445d-4877-fb9d-10f7ffa67fa6","executionInfo":{"status":"ok","timestamp":1552872846004,"user_tz":240,"elapsed":303388,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":1020}},"cell_type":"code","source":["#normalization+noise removal+image augmentation+square bounding box\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        temp_images.append([])\n","        img_idx = i\n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","        \n","        #with bounding box\n","        temp_images[i] = cv2.resize(b,(28,28))\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","#split data in train, validation, test\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","#pre processing it, resize it\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","# do something to fit in kera model---------------------------------------------\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","final_images = final_images.reshape(final_images.shape[0], 28, 28, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","final_images = final_images.astype('float32')\n","\n","#normalization\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]\n","#------------------------------------------------------------------------------\n","\n","#2d convolution----------------------------------------------------------------\n","# Three steps to Convolution\n","# 1. Convolution\n","# 2. Activation\n","# 3. Polling\n","# Repeat Steps 1,2,3 for adding more hidden layers\n","# 4. After that make a fully connected network\n","# This fully connected network gives ability to the CNN\n","# to classify the samples\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64,(3, 3)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","\n","# Fully connected layer\n","BatchNormalization()\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","#----------------------------------------------------------------------------------------\n","#generate additional images\n","\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","#--------------------------------------------------------------------------------\n","test_gen = ImageDataGenerator()\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n","\n","#fit the data and valid\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=10,validation_data=test_generator, validation_steps=4000//64)\n","\n","score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","X_train original shape (35000, 28, 28)\n","y_train original shape (35000,)\n","X_test original shape (4000, 28, 28)\n","y_test original shape (4000,)\n","Epoch 1/10\n","546/546 [==============================] - 17s 30ms/step - loss: 0.7855 - acc: 0.7597 - val_loss: 0.3645 - val_acc: 0.9052\n","Epoch 2/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.4286 - acc: 0.8855 - val_loss: 0.3020 - val_acc: 0.9337\n","Epoch 3/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.3626 - acc: 0.9056 - val_loss: 0.2935 - val_acc: 0.9372\n","Epoch 4/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.3307 - acc: 0.9146 - val_loss: 0.2765 - val_acc: 0.9411\n","Epoch 5/10\n","546/546 [==============================] - 16s 28ms/step - loss: 0.3160 - acc: 0.9191 - val_loss: 0.2488 - val_acc: 0.9466\n","Epoch 6/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.2954 - acc: 0.9264 - val_loss: 0.2484 - val_acc: 0.9449\n","Epoch 7/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.2857 - acc: 0.9261 - val_loss: 0.2589 - val_acc: 0.9464\n","Epoch 8/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.2763 - acc: 0.9303 - val_loss: 0.2551 - val_acc: 0.9489\n","Epoch 9/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.2660 - acc: 0.9337 - val_loss: 0.2866 - val_acc: 0.9433\n","Epoch 10/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.2546 - acc: 0.9366 - val_loss: 0.2410 - val_acc: 0.9502\n","4000/4000 [==============================] - 0s 112us/step\n","\n","Test accuracy:  0.94725\n"],"name":"stdout"}]},{"metadata":{"id":"SCUO4f3sz7oh","colab_type":"code","outputId":"045d090e-e8b8-4ee0-836d-7c3cb1b1d280","executionInfo":{"status":"ok","timestamp":1552873328741,"user_tz":240,"elapsed":163110,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":1020}},"cell_type":"code","source":["#normalization+noise removal+image augmentation+rectangle bounding box\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        temp_images.append([])\n","        img_idx = i\n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if w*h > largest_area:\n","                largest_area = w*h\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","        \n","        #with bounding box\n","        temp_images[i] = cv2.resize(b,(28,28))\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","\n","#split data in train, validation, test\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","#pre processing it, resize it\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","# do something to fit in kera model---------------------------------------------\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","\n","final_images = final_images.reshape(final_images.shape[0], 28, 28, 1)\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","final_images = final_images.astype('float32')\n","\n","#normalization\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","y_train[0], Y_train[0]\n","#------------------------------------------------------------------------------\n","\n","#2d convolution----------------------------------------------------------------\n","# Three steps to Convolution\n","# 1. Convolution\n","# 2. Activation\n","# 3. Polling\n","# Repeat Steps 1,2,3 for adding more hidden layers\n","# 4. After that make a fully connected network\n","# This fully connected network gives ability to the CNN\n","# to classify the samples\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64,(3, 3)))\n","model.add(Activation('relu'))\n","BatchNormalization(axis=-1)\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","\n","# Fully connected layer\n","BatchNormalization()\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","BatchNormalization()\n","model.add(Dropout(0.4))\n","model.add(Dense(10))\n","model.add(Activation('softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","#----------------------------------------------------------------------------------------\n","#generate additional images\n","\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","#--------------------------------------------------------------------------------\n","test_gen = ImageDataGenerator()\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n","\n","#fit the data and valid\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=10,validation_data=test_generator, validation_steps=4000//64)\n","\n","score = model.evaluate(X_test, Y_test)\n","print()\n","print('Test accuracy: ', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","X_train original shape (35000, 28, 28)\n","y_train original shape (35000,)\n","X_test original shape (4000, 28, 28)\n","y_test original shape (4000,)\n","Epoch 1/10\n","546/546 [==============================] - 17s 31ms/step - loss: 0.9408 - acc: 0.7181 - val_loss: 0.5437 - val_acc: 0.8672\n","Epoch 2/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.6141 - acc: 0.8390 - val_loss: 0.4649 - val_acc: 0.8867\n","Epoch 3/10\n","546/546 [==============================] - 16s 28ms/step - loss: 0.5552 - acc: 0.8582 - val_loss: 0.4425 - val_acc: 0.8905\n","Epoch 4/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.5214 - acc: 0.8677 - val_loss: 0.4277 - val_acc: 0.8928\n","Epoch 5/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.4956 - acc: 0.8741 - val_loss: 0.4284 - val_acc: 0.8935\n","Epoch 6/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.4747 - acc: 0.8803 - val_loss: 0.4284 - val_acc: 0.8991\n","Epoch 7/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.4648 - acc: 0.8813 - val_loss: 0.3948 - val_acc: 0.9073\n","Epoch 8/10\n","546/546 [==============================] - 16s 29ms/step - loss: 0.4513 - acc: 0.8854 - val_loss: 0.4119 - val_acc: 0.9004\n","Epoch 9/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.4383 - acc: 0.8881 - val_loss: 0.4267 - val_acc: 0.9060\n","Epoch 10/10\n","546/546 [==============================] - 15s 28ms/step - loss: 0.4248 - acc: 0.8885 - val_loss: 0.4308 - val_acc: 0.9022\n","4000/4000 [==============================] - 0s 114us/step\n","\n","Test accuracy:  0.90025\n"],"name":"stdout"}]}]}