{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pretrained_resnet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{},"source":["## Pretrained InceptionResNetV2 model"]},{"metadata":{"id":"H-hF14nz1Wd2","colab_type":"code","outputId":"fc790e40-4daf-4013-faea-1ffdf6b05c54","executionInfo":{"status":"ok","timestamp":1552915991925,"user_tz":240,"elapsed":10643094,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":1440}},"cell_type":"code","source":["#InceptionResNetV2\n","#learning rate=0.0002\n","#learning rate=0.0001 in the following cell will give a better result\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        img_idx = i\n","        temp_images.append([])\n","        temp_images[i] = cv2.resize(train_images[img_idx],(75,75))\n","        temp_images[i] = cv2.cvtColor(temp_images[i],cv2.COLOR_GRAY2BGR)\n","        \n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 75, 75\n","\n","X_train = X_train.reshape(X_train.shape[0], 75, 75, 3)\n","X_test = X_test.reshape(X_test.shape[0], 75, 75, 3)\n","\n","final_images = final_images.reshape(final_images.shape[0], 75, 75, 3)\n","\n","\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","# Build InceptionResNetV2 model\n","\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from keras.applications.densenet import DenseNet201\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras.applications.xception import Xception\n","\n","\n","\n","model = InceptionResNetV2(include_top=True, weights=None, input_tensor=None, input_shape=(75,75,3), pooling=\"avg\", classes=10)\n","\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0002), metrics=['accuracy'])\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08, featurewise_std_normalization=False)\n","\n","gen.fit(X_train)\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = gen.flow(X_test, Y_test, batch_size=64)\n","\n","\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=30,validation_data=test_generator, validation_steps=4000//64)\n","\n","\n","score = model.evaluate(gen.standardize(X_test), Y_test)\n","print()\n","print('Test accuracy: ', score[1])\n","\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import csv\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def write_output_csv(output_file,y_pred):\n","    with open(output_file, 'w') as csvfile:\n","        fieldnames = ['ImageId', 'Label']\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        writer.writeheader()\n","        for index in range(len(y_pred)):\n","            writer.writerow({'ImageId': index, 'Label': y_pred[index]})\n","\n","    \n","    \n","    return temp_images\n","test_images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/test_images.pkl')\n","X_test = get_data(test_images)\n","X_test = X_test.reshape(X_test.shape[0], 75, 75, 3)\n","\n","\n","import numpy as np\n","final_y = model.predict(X_test)\n","\n","final_y_result = [np.argmax(row) for row in final_y]\n","\n","index_list = [p for p in range(len(final_y_result))]\n","\n","df = pd.DataFrame({'Id':index_list, \"Category\":final_y_result}, columns=['Id', \"Category\"])\n","\n","df.to_csv(\"final_result.csv\",index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["X_train original shape (35000, 75, 75, 3)\n","y_train original shape (35000,)\n","X_test original shape (4000, 75, 75, 3)\n","y_test original shape (4000,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/30\n","546/546 [==============================] - 396s 726ms/step - loss: 1.4583 - acc: 0.5156 - val_loss: 1.5627 - val_acc: 0.5731\n","Epoch 2/30\n","546/546 [==============================] - 350s 641ms/step - loss: 0.5917 - acc: 0.8111 - val_loss: 0.8462 - val_acc: 0.7586\n","Epoch 3/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.3944 - acc: 0.8730 - val_loss: 0.4955 - val_acc: 0.8389\n","Epoch 4/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.2996 - acc: 0.9026 - val_loss: 0.9812 - val_acc: 0.7144\n","Epoch 5/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.2599 - acc: 0.9164 - val_loss: 0.3917 - val_acc: 0.8755\n","Epoch 6/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.2266 - acc: 0.9271 - val_loss: 0.3923 - val_acc: 0.8811\n","Epoch 7/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.2018 - acc: 0.9342 - val_loss: 0.5228 - val_acc: 0.8422\n","Epoch 8/30\n","546/546 [==============================] - 349s 639ms/step - loss: 0.1932 - acc: 0.9367 - val_loss: 0.4632 - val_acc: 0.8669\n","Epoch 9/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.1686 - acc: 0.9437 - val_loss: 0.3192 - val_acc: 0.9017\n","Epoch 10/30\n","546/546 [==============================] - 347s 635ms/step - loss: 0.1606 - acc: 0.9472 - val_loss: 0.4025 - val_acc: 0.8791\n","Epoch 11/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.1445 - acc: 0.9529 - val_loss: 0.4209 - val_acc: 0.8938\n","Epoch 12/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.1348 - acc: 0.9551 - val_loss: 0.2299 - val_acc: 0.9266\n","Epoch 13/30\n","546/546 [==============================] - 346s 635ms/step - loss: 0.1223 - acc: 0.9601 - val_loss: 0.2981 - val_acc: 0.9106\n","Epoch 14/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.1161 - acc: 0.9615 - val_loss: 0.2157 - val_acc: 0.9306\n","Epoch 15/30\n","546/546 [==============================] - 347s 635ms/step - loss: 0.1153 - acc: 0.9617 - val_loss: 0.2129 - val_acc: 0.9324\n","Epoch 16/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.1085 - acc: 0.9635 - val_loss: 0.2320 - val_acc: 0.9334\n","Epoch 17/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.0954 - acc: 0.9688 - val_loss: 0.1959 - val_acc: 0.9390\n","Epoch 18/30\n","546/546 [==============================] - 348s 637ms/step - loss: 0.0875 - acc: 0.9710 - val_loss: 0.2773 - val_acc: 0.9106\n","Epoch 19/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.0854 - acc: 0.9713 - val_loss: 0.2369 - val_acc: 0.9268\n","Epoch 20/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.0805 - acc: 0.9735 - val_loss: 0.2011 - val_acc: 0.9436\n","Epoch 21/30\n","546/546 [==============================] - 347s 635ms/step - loss: 0.0835 - acc: 0.9721 - val_loss: 0.1653 - val_acc: 0.9484\n","Epoch 22/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.0698 - acc: 0.9770 - val_loss: 0.2033 - val_acc: 0.9332\n","Epoch 23/30\n","546/546 [==============================] - 347s 635ms/step - loss: 0.0694 - acc: 0.9769 - val_loss: 0.2592 - val_acc: 0.9223\n","Epoch 24/30\n","546/546 [==============================] - 347s 635ms/step - loss: 0.0743 - acc: 0.9752 - val_loss: 0.1773 - val_acc: 0.9494\n","Epoch 25/30\n","546/546 [==============================] - 347s 636ms/step - loss: 0.0593 - acc: 0.9803 - val_loss: 0.2429 - val_acc: 0.9299\n","Epoch 26/30\n","546/546 [==============================] - 347s 635ms/step - loss: 0.0612 - acc: 0.9803 - val_loss: 0.2373 - val_acc: 0.9243\n","Epoch 27/30\n","546/546 [==============================] - 347s 635ms/step - loss: 0.0564 - acc: 0.9815 - val_loss: 0.1738 - val_acc: 0.9497\n","Epoch 28/30\n","546/546 [==============================] - 348s 638ms/step - loss: 0.0505 - acc: 0.9827 - val_loss: 0.2624 - val_acc: 0.9284\n","Epoch 29/30\n","546/546 [==============================] - 349s 638ms/step - loss: 0.0519 - acc: 0.9825 - val_loss: 0.2024 - val_acc: 0.9474\n","Epoch 30/30\n","546/546 [==============================] - 350s 642ms/step - loss: 0.0550 - acc: 0.9829 - val_loss: 1.9261 - val_acc: 0.6159\n","4000/4000 [==============================] - 14s 3ms/step\n","\n","Test accuracy:  0.61425\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"4twfm3GlcNmS","colab_type":"code","outputId":"361b2626-88a4-425b-c83e-dffa469eeeb0","executionInfo":{"status":"ok","timestamp":1552871014031,"user_tz":240,"elapsed":541497,"user":{"displayName":"姜垚","photoUrl":"","userId":"16388011331356283538"}},"colab":{"base_uri":"https://localhost:8080/","height":1003}},"cell_type":"code","source":["#learing rate=0.0001\n","%reset -f\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        img_idx = i\n","        temp_images.append([])\n","        temp_images[i] = cv2.resize(train_images[img_idx],(75,75))\n","        temp_images[i] = cv2.cvtColor(temp_images[i],cv2.COLOR_GRAY2BGR)\n","        \n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","        \n","        largest_dim = {\"x\":0, \"y\":0, \"w\":0, \"h\":0}\n","        largest_area = 0\n","        for num in contours:\n","            x,y,w,h = cv2.boundingRect(num)\n","            \n","            temp = 0\n","            \n","            if w > h:\n","                temp=w\n","            else:\n","                temp=h\n","                \n","            if temp*temp > largest_area:\n","                largest_area = temp*temp\n","                largest_dim[\"x\"] = x\n","                largest_dim[\"y\"] = y\n","                largest_dim[\"w\"] = w\n","                largest_dim[\"h\"] = h\n","        \n","\n","        b = threshed_img[largest_dim[\"y\"]:largest_dim[\"y\"]+largest_dim[\"h\"],largest_dim[\"x\"]:largest_dim[\"x\"]+largest_dim[\"w\"]]\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","  \n","def split_data(train_size, valid_size, test_size):\n","    images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_images.pkl')\n","    labels = pd.read_csv('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/train_labels.csv')\n","    return (images[:train_size], images[train_size:train_size+valid_size],images[train_size+valid_size:]),(labels[:train_size], labels[train_size:train_size+valid_size],labels[train_size+valid_size:])\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.optimizers import Adam, SGD\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","\n","np.random.seed(25)\n","\n","\n","\n","(X_train, X_test, final_images), (train_labels_new, test_labels_new, final_labels)=split_data(35000, 4000, 1000)\n","\n","X_train = get_data(X_train)\n","X_test = get_data(X_test)\n","final_images = get_data(final_images)\n","\n","y_train = np.array(train_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","y_test = np.array(test_labels_new[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","final_labels = np.array(final_labels[\"Category\"].tolist(), dtype=\"uint8\")\n","\n","print(\"X_train original shape\", X_train.shape)\n","print(\"y_train original shape\", y_train.shape)\n","print(\"X_test original shape\", X_test.shape)\n","print(\"y_test original shape\", y_test.shape)\n","\n","# input image dimensions\n","img_rows, img_cols = 75, 75\n","\n","# the data, split between train and test sets\n","X_train = X_train.reshape(X_train.shape[0], 75, 75, 3)\n","X_test = X_test.reshape(X_test.shape[0], 75, 75, 3)\n","\n","final_images = final_images.reshape(final_images.shape[0], 75, 75, 3)\n","\n","X_train/=255\n","X_test/=255\n","final_images/=255\n","\n","X_train.shape\n","\n","number_of_classes = 10\n","\n","Y_train = np_utils.to_categorical(y_train, number_of_classes)\n","Y_test = np_utils.to_categorical(y_test, number_of_classes)\n","\n","# InceptionResNetV2 model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from keras.applications.densenet import DenseNet201\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras.applications.xception import Xception\n","\n","\n","\n","model = InceptionResNetV2(include_top=True, weights=None, input_tensor=None, input_shape=(75,75,3), pooling=\"avg\", classes=10)\n","\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08, featurewise_std_normalization=False)\n","\n","gen.fit(X_train)\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)\n","test_generator = gen.flow(X_test, Y_test, batch_size=64)\n","\n","\n","history = model.fit_generator(train_generator, steps_per_epoch=35000//64, epochs=1,validation_data=test_generator, validation_steps=4000//64)\n","\n","\n","score = model.evaluate(gen.standardize(X_test), Y_test)\n","print()\n","print('Test accuracy: ', score[1])\n","\n","\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import csv\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","def write_output_csv(output_file,y_pred):\n","    with open(output_file, 'w') as csvfile:\n","        fieldnames = ['ImageId', 'Label']\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        writer.writeheader()\n","        for index in range(len(y_pred)):\n","            writer.writerow({'ImageId': index, 'Label': y_pred[index]})\n","def get_data(images):\n","    train_images = images\n","    temp_images = []\n","    \n","    for i in range(len(train_images)):\n","        img_idx = i\n","        temp_images.append([])\n","        temp_images[i] = cv2.resize(train_images[img_idx],(75,75))\n","        temp_images[i] = cv2.cvtColor(temp_images[i],cv2.COLOR_GRAY2BGR)\n","        \n","        image = np.ascontiguousarray(train_images[img_idx], dtype=np.uint8)\n","\n","        ret, threshed_img = cv2.threshold(image,\n","                        240, 255, cv2.THRESH_BINARY)\n","        img, contours, her = cv2.findContours(threshed_img, cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n","    \n","    temp_images = np.asarray(temp_images, dtype=np.float32)\n","    \n","    \n","    return temp_images\n","test_images = pd.read_pickle('gdrive/My Drive/Colab Notebooks/ML/comp551_project_3/input/test_images.pkl')\n","X_test = get_data(test_images)\n","X_test = X_test.reshape(X_test.shape[0], 75, 75, 3)\n","\n","\n","import numpy as np\n","final_y = model.predict(X_test)\n","final_y_result = [np.argmax(row) for row in final_y]\n","index_list = [p for p in range(len(final_y_result))]\n","df = pd.DataFrame({'Id':index_list, \"Category\":final_y_result}, columns=['Id', \"Category\"])\n","df.to_csv(\"final_result.csv\",index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["X_train original shape (35000, 75, 75, 3)\n","y_train original shape (35000,)\n","X_test original shape (4000, 75, 75, 3)\n","y_test original shape (4000,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/1\n","546/546 [==============================] - 415s 760ms/step - loss: 1.7805 - acc: 0.3892 - val_loss: 2.6016 - val_acc: 0.3483\n","4000/4000 [==============================] - 14s 4ms/step\n","\n","Test accuracy:  0.2805\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]}]}